{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import spacy\n",
    "from spacy import displacy\n",
    "import ast\n",
    "import re\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import sklearn\n",
    "import calendar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = pd.read_csv('tmdb_5000_movies.csv')\n",
    "credits = pd.read_csv('tmdb_5000_credits.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = movies.merge(credits,on = 'title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = movies[['id','title','overview','genres','keywords','cast','crew','spoken_languages','release_date']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.to_datetime(movies.iloc[0].release_date)\n",
    "movies['release_date'] = pd.to_datetime(movies['release_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies['year'] = movies['release_date'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = movies.drop(['release_date'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies['year'] = movies['year']//20\n",
    "# to make a group of 20 years movie ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "movies = movies.astype({'year':'string'})\n",
    "movies['year'].dtype\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Extract_tags(obj):\n",
    "    L = []\n",
    "    for i in eval(obj):\n",
    "        L.append(i['name'])\n",
    "    return L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies['genres'] = movies['genres'].apply(Extract_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies['keywords'] = movies['keywords'].apply(Extract_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Extract_cast(obj):\n",
    "    L = []\n",
    "    count = 0\n",
    "    for i in eval(obj):\n",
    "        if count > 3 :\n",
    "            break\n",
    "        L.append(i['name'])\n",
    "        count = count + 1\n",
    "    return L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies['cast'] = movies['cast'].apply(Extract_cast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "Id_overview = movies[['id','overview']]\n",
    "pickle.dump(Id_overview,open(\"ID_overview.pkl\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Extract_crew_director(obj):\n",
    "    L = []\n",
    "    for i in eval(obj):\n",
    "        if i['job'] == \"Director\" :\n",
    "            L.append(i['name'])\n",
    "            break\n",
    "    return L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies['crew'] = movies['crew'].apply(Extract_crew_director)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "id_crew = movies[['id','crew']]\n",
    "pickle.dump(Id_overview,open(\"ID_CREW.pkl\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "nlp_sm = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "def NRE_overview(obj):\n",
    "    all_orgs = []\n",
    "    ans = []\n",
    "    doc = nlp(obj)\n",
    "    for d in doc:\n",
    "        orgs = [d.text for ent in d.ent_type_ if d.ent_type_ == \"PERSON\" or d.ent_type_ == \"ORG\" or d.ent_type_ == \"NORP\" or d.ent_type_ == \"EVENT\" or d.ent_type_ == \"WORK_OF_ART\"]\n",
    "        all_orgs.extend(orgs)\n",
    "    l = Counter(all_orgs).most_common(15)\n",
    "    for i in l:\n",
    "        ans.append(i[0])    \n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies['overview'] = movies['overview'].apply(NRE_overview)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies['genres'] = movies['genres'].apply(lambda x : [i.replace(\" \",\"\") for i in x])\n",
    "movies['keywords'] = movies['keywords'].apply(lambda x : [i.replace(\" \",\"\") for i in x])\n",
    "movies['crew'] = movies['crew'].apply(lambda x : [i.replace(\" \",\"\") for i in x])\n",
    "movies['cast'] = movies['cast'].apply(lambda x : [i.replace(\" \",\"\") for i in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies['tags'] = movies['overview'] + movies['cast'] + movies['crew'] + movies['keywords'] + movies['genres'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Updated_dataframe = movies[['id','title','tags','year']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Updated_dataframe['tags'] = Updated_dataframe['tags'].apply(lambda x : \" \".join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Updated_dataframe['tags'] = Updated_dataframe['tags'] + \" \" + Updated_dataframe['year'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Updated_dataframe['tags'] = Updated_dataframe['tags'].apply(lambda x : x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Updated_dataframe.iloc[7].tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop_words(obj):\n",
    "    doc = obj\n",
    "    doc = doc.lower()\n",
    "    doc = doc.split()\n",
    "    doc = [lemmatizer.lemmatize(word) for word in doc if not word in set(stopwords)]\n",
    "    doc = ' '.join(doc)\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# movies['tags'] = movies['tags'].apply(remove_stop_words)\n",
    "Updated_dataframe['tags'] = Updated_dataframe['tags'].apply(remove_stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem(text):\n",
    "    y = []\n",
    "    for i in text.split():\n",
    "        y.append(ps.stem(i)) \n",
    "    return \" \".join(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Updated_dataframe['tags'] = Updated_dataframe['tags'].apply(stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_tags = list(Updated_dataframe['tags'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer() \n",
    "vectors = vectorizer.fit_transform(list_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"n_samples: %d, n_features: %d\" % vectors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the first five documents from the data set\n",
    "tf_idf = pd.DataFrame(vectors.todense())\n",
    "tf_idf.columns = vectorizer.get_feature_names_out()\n",
    "tfidf_matrix = tf_idf.T\n",
    "# columns are the movies\n",
    "# rows are the features/tags extracted \n",
    "tfidf_matrix.columns = [Updated_dataframe.iloc[i].title for i in range(0, 4805)]\n",
    "tfidf_matrix['count'] = tfidf_matrix.sum(axis=1)\n",
    "# All  features to be used \n",
    "# *************  PLEASE CHECK WITH DIFFERNT NUMBER OF ALLOWED FEATURE , TOp 100 or something like that ***************\n",
    "tfidf_matrix = tfidf_matrix.sort_values(by ='count', ascending=False)[:1000] \n",
    "# Print the whole matrix\n",
    "print(tfidf_matrix.drop(columns=['count']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_matrix.drop(['count'], axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Vectorirsed_data = tfidf_matrix.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Vectorirsed_data.iloc[0].sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy_vector_form_data = Vectorirsed_data.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interaction_vector_movies = cosine_similarity(numpy_vector_form_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend(movie):\n",
    "    index_movie = Updated_dataframe[Updated_dataframe['title'] == movie].index[0]\n",
    "    movie_vector =sorted( list( enumerate(interaction_vector_movies[index_movie])) , reverse=True , key = lambda x:x[1])\n",
    "    for i in range(1,11):\n",
    "        print(Updated_dataframe.iloc[movie_vector[i][0]].id)\n",
    "        print(Updated_dataframe.iloc[movie_vector[i][0]].title)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommend('Batman Begins')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(Updated_dataframe , open('Movies_re.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(interaction_vector_movies ,open(\"interaction_vector_movies.pkl\",'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
